---
title: "Graded Assignment: Data Analysis Project"
subtitle: "Bayesian Statistics Specialization: Course 2, Techniques and Models"
author: "Tiago B. Lacerda"
date: "2025-05-11"
output:
  pdf_document:
    latex_engine: xelatex
header-includes:
  - \usepackage{fontspec}
  - \usepackage{amsmath}
  - \usepackage[utf8]{inputenc}
  - \usepackage{pdflscape}
  - \setlength{\tabcolsep}{3pt}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{r libraries, message=FALSE, warning=FALSE, include=FALSE}
library(readxl)
library(dplyr)
library(rjags)
library(coda)
library(tidybayes)
library(tidyr)
library(HDInterval)
library(writexl)
library(tidyverse)
start_time <- Sys.time()
```

# Executive Summary

This report presents a comprehensive analysis of the Excellent Consistent Quality (ECQ) success rate across various network sites in Brazil's Northeast region. The primary objective is to identify sites with significantly lower ECQ success probabilities compared to the network average, enabling targeted interventions for network improvement. A three-level Bayesian hierarchical model is employed to account for data scarcity and local variability, providing stable estimates of each site's true ECQ success probability. The analysis reveals critical insights into site performance, guiding data-informed investment decisions.

# Introduction

In contemporary 4G and 5G mobile networks, operators must efficiently allocate limited resources to ensure high service quality. A pivotal metric in this context is the Excellent Consistent Quality (ECQ) success rate at individual sites. ECQ assessments evaluate whether networks consistently support demanding applications such as video streaming, video calls, and gaming, ensuring a seamless user experience. These tests are typically conducted with embedded SDKs in applications. They measure KPIs including download speed, upload speed, latency, jitter, packet loss, and time to first byte, aligning with thresholds recommended for various demanding applications. However, the variability in the number of tests across sites—some reporting only a handful while others report hundreds due to natural user mobility—poses a significant challenge. Naïve "site-by-site" estimates can be misleading: small samples may produce extreme rates simply due to chance, and citywide averages can obscure localized underperformance. To address this, a three-level Bayesian hierarchical model is proposed, nesting individual sites within municipalities and municipalities within ANFs.

### Problem Definition

Our network comprises multiple sites scattered across a city, each running a varying number of ECQ tests. Some sites may report as few as 5–20 tests in a given period, while others conduct several hundred. The core challenge is to identify which sites genuinely underperform in terms of ECQ success rate and thus prioritize network improvement investments, without being misled by the randomness inherent in small test counts.

#### Specific Question

> *Which sites have a true ECQ success probability significantly below the network average, and how can rank them for targeted interventions, accounting for both data scarcity and local variability?*

By formalizing this question, we set the stage for applying a hierarchical Bayes model that “borrows strength” across sites and municipalities, producing posterior distributions for each site’s success probability. These posteriors underpin credible intervals and ranking metrics that guide robust, data-informed investment decisions.

### Data

In this report, we analyze ECQ test data collected in October 2024 across Brazil's Northeast region, encompassing 8 ANFs. Each data point corresponds to a specific network site, identified by its unique ENDERECO_ID. For every site, we have recorded the total number of ECQ tests conducted and the number of successful tests (TESTES_ECQ_OK), indicating instances where the network met the stringent performance thresholds defined by the ECQ metric.

```{r Leitura dos dados, echo=FALSE, message=FALSE, warning=FALSE}
data <- read_excel("ECQ_OUT_24.xlsx", sheet = "Export") %>%
  filter(ANF %in% c(83, 81)) %>%
  mutate(TESTES_ECQ_OK = round(TESTES_ECQ * ECQ, 0))  # Recriar a variável resposta

# Criar IDs únicos para grupos (agora só ANF 83)
data <- data %>%
  group_by(ANF, MUNICIPIO) %>%
  mutate(group_id = cur_group_id()) %>%
  ungroup() %>% 
  select(group_id, ANF, MUNICIPIO, ENDERECO_ID, TESTES_ECQ_OK, TESTES_ECQ)

# Mapeamento de grupos para ANF (só 1 ANF agora)
group_df <- data %>%
  distinct(group_id, ANF) %>%
  arrange(group_id)


```

Below is a summary of the data we will be using in our analysis.

```{r DATA Structure, echo=FALSE, message=FALSE, warning=FALSE}
str(data)
```

```{r PLOT, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

library(ggplot2)
library(ggrepel)
library(dplyr)  

data_amostrada <- data %>% 
  slice_sample(prop = 0.5)  # ou sample_n(100) para 100 pontos fixos

ggplot(data_amostrada, aes(
      x = TESTES_ECQ,
      y = TESTES_ECQ_OK / TESTES_ECQ,
      label = ENDERECO_ID
    )) +
  geom_point(size = 2, alpha = 0.7) +
  geom_text_repel(
    size = 3,
    max.overlaps = 5
  ) +
  scale_y_continuous(labels = scales::percent_format(1)) +
  labs(
    title = "ECQ Tests vs. Success Rate (Random Sample)",
    x = "Number of ECQ Tests",
    y = "Success Rate (ECQ_OK / ECQ)",
    caption = "Points represent a random sample of network sites (ENDERECO_ID)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.title = element_text(face = "bold")
  )

```

## Bayesian Model Structure

Model structure definition in JAGS.


```{r JAGS, message=FALSE, warning=FALSE, include=FALSE}
jags_data <- list(
  N_group = max(data$group_id),
  N_sites = nrow(data),
  group_per_site = data$group_id,  # Vetor de grupos por site
  n_tests = data$TESTES_ECQ,       # Vetor de testes
  n_success = data$TESTES_ECQ_OK   # Vetor de sucessos
)

```

```{r JAGS MODEL STRING, echo=TRUE}
model_string <- "
model {
  # Hiperparâmetros globais
  mu_global ~ dbeta(3, 3)
  sigma_global ~ dgamma(2, 0.5)  # Prior Gamma mais informativa

  # Parâmetros ANF com restrição
  alpha_anf <- mu_global * sigma_global
  beta_anf <- (1 - mu_global) * sigma_global 
  mu_anf ~ dbeta(alpha_anf, beta_anf)

  # Priors para dispersão
  phi_municipio ~ dgamma(2, 0.9)  # Gamma mais suave
  phi_site ~ dgamma(2, 2)

  # Loop por municípios
  for(g in 1:N_group) {
    a_municipio[g] <- mu_anf * phi_municipio
    b_municipio[g] <- (1 - mu_anf) * phi_municipio
    mu_municipio[g] ~ dbeta(a_municipio[g], b_municipio[g])
  }

  # Loop por sites
  for(s in 1:N_sites) {
    logit_mu_site[s] <- logit(mu_municipio[group_per_site[s]])
    theta_site[s] <- ilogit(logit_mu_site[s] + epsilon[s])
    epsilon[s] ~ dnorm(0, 1/phi_site)
    
    n_success[s] ~ dbin(theta_site[s], n_tests[s])
  }
}
"
```

```{r JAGS RUN, message=FALSE, warning=FALSE, include=FALSE}

inits <- function() {
  list(
    mu_global = rbeta(1, 3, 3),
    sigma_global = rgamma(1, 2, 0.5),  # Coerente com o prior
    phi_municipio = rgamma(1, 2, 2),
    phi_site = rgamma(1, 2, 2),
    mu_anf = rbeta(1, 2, 2)  # Inicialização direta
    
  )
}

model <- jags.model(
  textConnection(model_string),
  data = jags_data,
  inits = inits,
  n.chains = 4,
  n.adapt = 1000  # Aumentar fase de adaptação
)

samples <- coda.samples(
  model,
  variable.names = c("mu_anf", "mu_municipio", "theta_site"),
  n.iter = 5000,
  thin = 2
)
```

```{r df_final, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
#Analise 
# 1. Mapear group_id para ANF e Município
group_map <- data %>%
  distinct(group_id, ANF, MUNICIPIO)

# 2. Extrair estatísticas dos municípios
municipio_stats <- samples %>%
  spread_draws(mu_municipio[group_id]) %>%
  group_by(group_id) %>%
  summarise(
    mean_municipio = mean(mu_municipio),
    stddev_municipio = sd(mu_municipio),
    hdi_inf_Mun = hdi(mu_municipio, credMass = 0.95)[1],
    hdi_sup_Mun = hdi(mu_municipio, credMass = 0.95)[2]
  ) %>%
  left_join(group_map, by = "group_id")

# 3. Extrair estatísticas dos sites
site_stats <- samples %>%
  spread_draws(theta_site[site_index]) %>%  # site_index corresponde à ordem nos dados originais
  group_by(site_index) %>%
  summarise(
    mean_site = mean(theta_site),
    stddev_site = sd(theta_site),
    hdi_inf = hdi(theta_site, credMass = 0.95)[1],
    hdi_sup = hdi(theta_site, credMass = 0.95)[2]
  ) %>%
  mutate(site_index = as.integer(site_index))

# 4. Combinar com dados originais
final_df <- data %>%
  mutate(site_index = row_number()) %>%  # Criar índice correspondente ao theta_site
  left_join(site_stats, by = "site_index") %>%
  left_join(municipio_stats, by = c("group_id", "ANF", "MUNICIPIO")) %>%
  mutate(
    FALHAS_ECQ = TESTES_ECQ - TESTES_ECQ_OK,
    # Calcular métricas de impacto
    FALHAS_ECQ_norm = (FALHAS_ECQ - min(FALHAS_ECQ)) / 
      (max(FALHAS_ECQ) - min(FALHAS_ECQ) + 1e-8),
    impacto = (1 - mean_site) * FALHAS_ECQ_norm,
    rank = dense_rank(desc(impacto))
  ) %>%
  select(
    ANF, MUNICIPIO, ENDERECO_ID,
    hdi_inf, mean_site, hdi_sup,
    hdi_inf_Mun, mean_municipio, hdi_sup_Mun,
    TESTES_ECQ, TESTES_ECQ_OK, FALHAS_ECQ,
    impacto, rank
  ) %>%
  arrange(ANF, MUNICIPIO, rank)

# 5. Verificar e exportar
if(nrow(final_df) == nrow(data)) {
  write_xlsx(final_df, "priorizacao_sites_ECQ_R_OUT24.xlsx")
  message("Arquivo exportado com sucesso!")
} else {
  warning("Verificar correspondência entre índices e dados!")
}


# Verificar primeiros rankings
#final_df %>%
#  select(ENDERECO_ID, impacto, rank) %>%
#  head(10)

# Extrair amostras de mu_anf
mu_anf_samples <- samples %>%
  spread_draws(mu_anf) %>%  # Extrai todas as amostras
  mutate(parameter = "mu_anf")  # Para identificação

# Calcular estatísticas sumárias
mu_anf_stats <- mu_anf_samples %>%
  group_by(parameter) %>%
  summarise(
    mean = mean(mu_anf),
    std_dev = sd(mu_anf),
    hdi_3 = hdi(mu_anf, credMass = 0.94)[1],
    hdi_97 = hdi(mu_anf, credMass = 0.94)[2]
  )

# Formatar para exibição
mu_anf_formatted <- mu_anf_stats %>%
  mutate(
    across(c(mean, std_dev, hdi_3, hdi_97), ~ round(., 3)),
    hdi_interval = glue::glue("[{hdi_3}, {hdi_97}]")
  ) %>%
  select(parameter, mean, std_dev, hdi_interval)

final_df_mun <- final_df %>% 
  select(-TESTES_ECQ, -TESTES_ECQ_OK, -FALHAS_ECQ)

```


### Conclusions
The application of the Bayesian hierarchical model enabled the identification of sites with performance significantly below average, highlighting priority areas for intervention. The consideration of credible intervals in the estimates reinforces the need for actions based on robust statistical evidence, aiming for the continuous improvement of network quality.

This approach allows for a nuanced understanding of performance variability across different sites and municipalities, ensuring that interventions are targeted where they are most needed. By quantifying uncertainty through credible intervals, decision-makers can assess the reliability of the estimates and prioritize actions with greater confidence.


In summary, the Bayesian hierarchical model provides a comprehensive framework for identifying underperforming areas and supports evidence-based decision-making to enhance overall network quality.



\newpage
\begin{landscape}
```{r Tabela, echo=FALSE, message=FALSE, warning=FALSE}

library(kableExtra)
library(dplyr)
final_df <- final_df%>% arrange(desc(impacto))
# Format numeric columns & translate headers

# Aqui fazemos o mesmo pipeline de antes:
pretty_head <- final_df %>%
  arrange(desc(impacto)) %>%
  slice_head(n = 35) %>%
  mutate(
    across(
      c(hdi_inf, mean_site, hdi_sup,
        hdi_inf_Mun, mean_municipio, hdi_sup_Mun,
        impacto),
      ~ round(., 2)
    ),
    rank = as.integer(rank)
  ) %>%
  rename(
    City           = MUNICIPIO,
    Site                = ENDERECO_ID,
    `HDI Inf.`          = hdi_inf,
    `Avg.`        = mean_site,
    `HDI Sup.`          = hdi_sup,
    `HDI Inf`     = hdi_inf_Mun,
    `Avg`   = mean_municipio,
    `HDI Sup`     = hdi_sup_Mun,
    Test              = TESTES_ECQ,
    Succ            = TESTES_ECQ_OK,
    Fail              = FALHAS_ECQ,
    Impact             = impacto,
    Prio          = rank
  )
pretty_head %>%
  kable(
    caption = "Amostra de Sites Prioritários",
    align   = c("l", "l", "l", rep("c", 11)),
    escape  = FALSE
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width        = FALSE,
    font_size         = 8
  ) %>%
  # Cabeçalho de primeiro nível (agrupando colunas)
  add_header_above(c(
    " "                = 1,  # blank para rownames implícitos
    "Identificação"    = 2,  # Município + Site
    "Site — HDI"       = 3,  # HDI Inf / Média Site / HDI Sup
    "Município — HDI"  = 3,  # HDI Mun. Inf / Média Município / HDI Mun. Sup
    "Testes"           = 3,  # Testes / Sucessos / Falhas
    "Impacto / Pri."   = 2   # Impacto + Prioridade
  )) %>%
  # Segundo nível: a linha de nomes original fica em negrito e cor de fundo
  row_spec(0, bold = TRUE, background = "#005b96", color = "white") %>%
  # Reduz padding das células
  column_spec(1:14, extra_css = "padding:2px 4px;") %>%
  # Destaques pontuais
  column_spec(4:7, background = "#f7f7f7") %>%
  column_spec(12, color = "white", background = "#d7191c")



```
\end{landscape}